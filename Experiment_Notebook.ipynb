{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import SE\n",
    "import SO\n",
    "from util import generate_groups, generate_non_overlap, generate_means\n",
    "from Grouped_Bandit import gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - Investigation of effect of gap value $\\Delta$\n",
    "- We consider how the total sample compleixty (represented by total arm pulls) and accuracy of the algorithms outlined are affected by the value of $\\Delta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust model variable\n",
    "c_val=1\n",
    "eta=0.01\n",
    "num_groups=10\n",
    "num_arms=100\n",
    "thy=0\n",
    "gap_list=[0.1, 0.2, 0.4]\n",
    "\n",
    "# Adjust experiment variable\n",
    "num_trials=10\n",
    "num_seeds=10\n",
    "\n",
    "result = dict()\n",
    "for seed_i in range(num_seeds):\n",
    "    # Set seed\n",
    "    seed = seed_i\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    gaps_info = {}\n",
    "    for gap in gap_list:\n",
    "        groups = generate_groups(num_groups, num_arms)\n",
    "        means = generate_means(num_groups, num_arms, gap, groups)\n",
    "        gb1 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=groups, means=means)\n",
    "        gb2 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb1.groups, means=gb1.true_means)\n",
    "\n",
    "        # Record experimental results\n",
    "        succ_count_list_SE = []\n",
    "        succ_count_list_SO = []\n",
    "        arm_pulls_list_SE = []\n",
    "        arm_pulls_list_SO = []\n",
    "        for trial_idx in range(num_trials):\n",
    "            \n",
    "            G_final = SE.succ_elim(gb1, thy)\n",
    "            \n",
    "            ## 1 if the result is correct, 0 otherwise\n",
    "            if set(G_final).issubset(set(gb1.find_true_objectives())):\n",
    "                succ_count_list_SE.append(1)\n",
    "            else:\n",
    "                succ_count_list_SE.append(0)\n",
    "\n",
    "            arm_pulls_list_SE.append(gb1.compute_total_arm_pulls())\n",
    "            print(gb1.compute_total_arm_pulls())\n",
    "            gb1 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb1.groups, means=gb1.true_means)\n",
    "        print('SE done')\n",
    "        for trial_idx in range(num_trials):\n",
    "            G_final_2 = SO.stable_opt(gb2, c_val, eta)\n",
    "            if set(G_final_2).issubset(set(gb2.find_true_objectives())):\n",
    "                succ_count_list_SO.append(1)\n",
    "            else:\n",
    "                succ_count_list_SO.append(0)\n",
    "\n",
    "            arm_pulls_list_SO.append(gb2.compute_total_arm_pulls())\n",
    "            print(gb2.compute_total_arm_pulls())\n",
    "            gb2 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb2.groups, means=gb2.true_means)\n",
    "        succ_rate_SE = sum(succ_count_list_SE) / num_trials\n",
    "        succ_rate_SO = sum(succ_count_list_SO) / num_trials\n",
    "        avg_num_pulls_SE = sum(arm_pulls_list_SE) / num_trials\n",
    "        print(f'{gap}, SE: {succ_rate_SE}, SO: {succ_rate_SO}, pulls: {avg_num_pulls_SE}')\n",
    "        gaps_info[gap] = {'succ_count_list_SE': succ_count_list_SE, 'succ_count_list_SO': succ_count_list_SO, \n",
    "                             'arm_pulls_list_SE': arm_pulls_list_SE, 'arm_pulls_list_SO': arm_pulls_list_SO}\n",
    "\n",
    "    result[seed] = gaps_info\n",
    "\n",
    "### Save into \\Results folder\n",
    "with open(f'Results/gap_value_c={c_val}_conf={eta}.pickle', 'wb') as handle:\n",
    "    pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - Comparison to the Naive approach\n",
    "- In our implementation, we consider a comparison between the SE algorithm and the group-wise naive UCB approach discussed in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust model variable\n",
    "c_val=1\n",
    "eta=0.01\n",
    "num_groups=10\n",
    "num_arms=100\n",
    "thy=0\n",
    "gap_list=[0.1, 0.2, 0.4]\n",
    "\n",
    "# Adjust experiment variable\n",
    "num_trials=10\n",
    "num_seeds=10\n",
    "\n",
    "naive_result_non_overlap = dict()\n",
    "for seed_i in range(num_seeds):\n",
    "    # Set seed\n",
    "    seed = seed_i\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    gaps_info = {}\n",
    "    for gap in gap_list:\n",
    "        groups = generate_non_overlap(num_groups,num_arms)\n",
    "        means = generate_means(num_groups,num_arms,gap,groups)\n",
    "        gb1 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=groups, means=means)\n",
    "        gb2 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb1.groups, means=gb1.true_means)\n",
    "\n",
    "        # Store emperimental results\n",
    "        succ_count_list_SE = []\n",
    "        succ_count_list_naive = []\n",
    "        arm_pulls_list_SE = []\n",
    "        arm_pulls_list_naive = []\n",
    "        for trial_idx in range(num_trials):\n",
    "            G_final = SE.succ_elim(gb1, thy)\n",
    "            \n",
    "            ## 1 if the result is correct, 0 otherwise\n",
    "            if set(G_final).issubset(set(gb1.find_true_objectives())):\n",
    "                succ_count_list_SE.append(1)\n",
    "            else:\n",
    "                succ_count_list_SE.append(0)\n",
    "\n",
    "            arm_pulls_list_SE.append(gb1.compute_total_arm_pulls())\n",
    "            print(gb1.compute_total_arm_pulls())\n",
    "            gb1 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb1.groups, means=gb1.true_means)\n",
    "        print('SE done')\n",
    "        for trial_idx in range(num_trials):\n",
    "            G_final_2 = Naive_UCB.group_wise_UCB(gb2, c_val, eta)\n",
    "            if set(G_final_2).issubset(set(gb2.find_true_objectives())):\n",
    "                succ_count_list_naive.append(1)\n",
    "            else:\n",
    "                succ_count_list_naive.append(0)\n",
    "\n",
    "            arm_pulls_list_naive.append(gb2.compute_total_arm_pulls())\n",
    "            print(gb2.compute_total_arm_pulls())\n",
    "            gb2 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb2.groups, means=gb2.true_means)\n",
    "        succ_rate_SE = sum(succ_count_list_SE) / num_trials\n",
    "        succ_rate_naive = sum(succ_count_list_naive) / num_trials\n",
    "        print(f'{gap}, SE: {succ_rate_SE}, naive:{succ_rate_naive}')\n",
    "        gaps_info[gap] = {'succ_count_list_SE': succ_count_list_SE, 'succ_count_list_naive': succ_count_list_naive, \n",
    "                             'arm_pulls_list_SE': arm_pulls_list_SE, 'arm_pulls_list_naive': arm_pulls_list_naive}\n",
    "\n",
    "    naive_result_non_overlap[seed] = gaps_info\n",
    "\n",
    "### Save into \\Results folder  \n",
    "with open(f'Results/naive_non_overlap_c={c_val}_conf={eta}.pickle', 'wb') as handle:\n",
    "    pickle.dump(naive_result_non_overlap, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - Different Bound Expressions (Theoretical vs Simplified choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust model variable\n",
    "c_val=1\n",
    "eta=0.01\n",
    "num_groups=10\n",
    "num_arms=100\n",
    "gap_list=[0.1, 0.2, 0.4]\n",
    "\n",
    "# Adjust experiment variable\n",
    "num_trials=10\n",
    "num_seeds=10\n",
    "\n",
    "result={}\n",
    "for gap in gap_list:\n",
    "    \n",
    "    gaps_info= {}\n",
    "    for seed in range(num_seeds):\n",
    "        # Set seed\n",
    "        np.random.seed(seed)\n",
    "        groups = generate_groups(num_groups, num_arms)\n",
    "        means = generate_means(num_groups, num_arms, gap, groups)\n",
    "        gb1 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=groups, means=means)\n",
    "        gb2 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb1.groups, means=gb1.true_means)\n",
    "        \n",
    "        # Store experimental results\n",
    "        succ_count_list_SE = []\n",
    "        succ_count_list_Theoretical = []\n",
    "        arm_pulls_list_SE = []\n",
    "        arm_pulls_list_Theoretical = []\n",
    "        for trial_idx in range(num_trials):\n",
    "            G_final = SE.succ_elim(gb1, thy=0)\n",
    "            if set(G_final).issubset(set(gb1.find_true_objectives())):\n",
    "                succ_count_list_SE.append(1)\n",
    "            else:\n",
    "                succ_count_list_SE.append(0)\n",
    "\n",
    "            arm_pulls_list_SE.append(gb1.compute_total_arm_pulls())\n",
    "            print(gb1.compute_total_arm_pulls())\n",
    "            gb1 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb1.groups, means=gb1.true_means)\n",
    "        print('done')\n",
    "        for trial_idx in range(num_trials):\n",
    "            G_final_2 = SE.succ_elim(gb2, thy=1)\n",
    "            if set(G_final_2).issubset(set(gb2.find_true_objectives())):\n",
    "                succ_count_list_Theoretical.append(1)\n",
    "            else:\n",
    "                succ_count_list_Theoretical.append(0)\n",
    "\n",
    "            arm_pulls_list_Theoretical.append(gb2.compute_total_arm_pulls())\n",
    "            print(gb2.compute_total_arm_pulls())\n",
    "            gb2 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=gb2.groups, means=gb2.true_means)\n",
    "        succ_rate_SE = sum(succ_count_list_SE) / num_trials\n",
    "        succ_rate_Theoretical = sum(succ_count_list_Theoretical) / num_trials\n",
    "        print(f'{seed}, SE: {succ_rate_SE}, Simple: {succ_rate_Theoretical}')\n",
    "        gaps_info[seed] = {'succ_count_list_SE': succ_count_list_SE, 'succ_count_list_Theoretical': succ_count_list_Theoretical, \n",
    "                              'arm_pulls_list_SE': arm_pulls_list_SE, 'arm_pulls_list_Theoretical': arm_pulls_list_Theoretical}\n",
    "    result[gap] = gaps_info\n",
    "    \n",
    "import pickle\n",
    "with open(f'Results/bound_c={c_val}.pickle', 'wb') as handle:\n",
    "    pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - Simple Regret for different algorithms stopping criterions and gap values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StableOpt Functions\n",
    "You have the following choices of optimizer selection criterion for StableOpt:\n",
    "1. `gb2_minmax_mean`: current group with highest worst-case mean\n",
    "2. `gb2_minmax_lcb`: current group with highest worst-case LCB value\n",
    "3. `gb2_history_lcb`: the group with highest worst-case LCB value from the start of algorithm run to current iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust model variable\n",
    "c_val=1\n",
    "eta=0.01\n",
    "num_groups=10\n",
    "num_arms=100\n",
    "thy=0\n",
    "gap_list=[0.1, 0.2, 0.4]\n",
    "\n",
    "# Adjust experiment variable\n",
    "num_trials=100\n",
    "seed=0\n",
    "\n",
    "# Choice of stopping criterion (1 if the result is recorded in the dt)\n",
    "minmax_mean=1\n",
    "minmax_lcb=1\n",
    "history_lcb=1\n",
    "\n",
    "result = {}\n",
    "\n",
    "for gap in gap_list:\n",
    "    # Set seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Initialize base instance\n",
    "    groups = generate_groups(num_groups, num_arms)\n",
    "    means = generate_means(num_groups, num_arms, gap, groups)\n",
    "    gb0 = gb(num_groups=num_groups, num_arms=num_arms, c=c_val, gap=gap, dist='bernoulli', groups=groups, means=means)\n",
    "    \n",
    "    count = 0\n",
    "    gap_result = {}\n",
    "\n",
    "    for k in range(num_trials):\n",
    "        gb1 = gb(num_groups=num_groups, num_arms=num_arms, groups=gb0.groups, means=gb0.true_means, c=c_val, gap=gap) # instance for SE\n",
    "        gb2 = gb(num_groups=num_groups, num_arms=num_arms, groups=gb0.groups, means=gb0.true_means, c=c_val, gap=gap) # instance for StableOpt\n",
    "\n",
    "        # param for StableOpt\n",
    "        G_list = []\n",
    "        curr_list = []\n",
    "        history_best_l = -1 ## history best lcb candidate\n",
    "        history_best_lcb = 0\n",
    "\n",
    "        # param for SE\n",
    "        m = gb1.groups\n",
    "        c = np.arange(gb1.num_groups)\n",
    "\n",
    "        ## instance data (we include all )\n",
    "        true_optimal_group = gb0.find_true_objectives()\n",
    "        true_optimal_min = min(gb0.true_means[gb1.groups[true_optimal_group][0]])\n",
    "        result['true_optimal_group'] = true_optimal_group\n",
    "        result['true_optimal_min'] = true_optimal_min\n",
    "        \n",
    "        gb1_summary = {}\n",
    "        gb1_summary['gb1_minmax_lcb_val'] = []\n",
    "        gb1_summary['gb1_minmax_lcb_G'] = []\n",
    "        gb1_summary['gb1_minmax_lcb_regret'] = []\n",
    "        gb1_summary['pulls'] = []\n",
    "        \n",
    "        gb2_summary = {}\n",
    "        if minmax_mean:\n",
    "            gb2_summary['gb2_minmax_mean_val'] = []\n",
    "            gb2_summary['gb2_minmax_mean_G'] = []\n",
    "            gb2_summary['gb2_minmax_mean_regret'] = []\n",
    "        if minmax_lcb:\n",
    "            gb2_summary['gb2_minmax_lcb_val'] = []\n",
    "            gb2_summary['gb2_minmax_lcb_G'] = []\n",
    "            gb2_summary['gb2_minmax_lcb_regret'] = []\n",
    "        if history_lcb:\n",
    "            gb2_summary['gb2_history_lcb_val'] = []\n",
    "            gb2_summary['gb2_history_lcb_G'] = []\n",
    "            gb2_summary['gb2_history_lcb_regret'] = []\n",
    "        \n",
    "        while c.size > 1:\n",
    "\n",
    "            # One iteration for SE (begin)\n",
    "            m = SE.compute_m_t(c, m, gb1, thy)\n",
    "            c = SE.compute_c_t(c, m, gb1, thy)\n",
    "            a = SE.compute_a_t(c, m)\n",
    "\n",
    "            pulls = int(gb1.compute_total_arm_pulls() - gb2.compute_total_arm_pulls())\n",
    "            if pulls > 0 and gb1.iter:\n",
    "                lcb_t = gb1.empirical_means - (c_val / np.sqrt(gb1.individual_arm_pulls))\n",
    "                \n",
    "                gb1_minmax_lcb_val = np.array([lcb_t[g].min() for g in gb1.groups]).max()\n",
    "                gb1_minmax_lcb_Gs = np.argwhere([lcb_t[g].min() for g in gb1.groups] == gb1_minmax_lcb_val).reshape(1,-1)[0]\n",
    "                gb1_minmax_lcb_G = np.random.choice(gb1_minmax_lcb_Gs, 1)\n",
    "                gb1_minmax_lcb_G_mean = gb1.true_means[gb1.groups[gb1_minmax_lcb_G][0]].min()\n",
    "\n",
    "                gb1_summary['gb1_minmax_lcb_val'].append(gb1_minmax_lcb_G_mean)\n",
    "                gb1_summary['gb1_minmax_lcb_G'].append(gb1_minmax_lcb_G)\n",
    "                gb1_summary['gb1_minmax_lcb_regret'].append(true_optimal_min - gb1_minmax_lcb_G_mean)\n",
    "                gb1_summary['pulls'].append(gb1.compute_total_arm_pulls())\n",
    "\n",
    "            # One iteration for StableOpt with num of pulls equal to SE's one iteration\n",
    "            for i in range(pulls) :\n",
    "                ucb_t = gb2.empirical_means + (c_val / np.sqrt(gb2.individual_arm_pulls))\n",
    "                lcb_t = gb2.empirical_means - (c_val / np.sqrt(gb2.individual_arm_pulls))\n",
    "\n",
    "                G_t = SO.select_G_t(gb2, ucb_t)\n",
    "                a_t = SO.select_a_t(gb2, lcb_t, G_t)\n",
    "\n",
    "                if i == (pulls - 1):\n",
    "                    gb2_minmax_mean_val = np.array([gb2.empirical_means[g].min() for g in gb2.groups]).max()\n",
    "                    gb2_minmax_mean_G = np.argwhere([gb2.empirical_means[g].min() for g in gb2.groups] == gb2_minmax_mean_val).reshape(1,-1)[0]\n",
    "                    gb2_minmax_mean_G_mean = gb2.true_means[gb2.groups[gb2_minmax_mean_G][0]].min()\n",
    "                    gb2_minmax_lcb_val = np.array([lcb_t[g].min() for g in gb2.groups]).max()\n",
    "                    gb2_minmax_lcb_G = np.argwhere([lcb_t[g].min() for g in gb2.groups] == gb2_minmax_lcb_val).reshape(1,-1)[0]\n",
    "                    gb2_minmax_lcb_G_mean = gb2.true_means[gb2.groups[gb2_minmax_lcb_G][0]].min()\n",
    "\n",
    "                history_best_l_mean = gb2.true_means[gb2.groups[history_best_l]].min()\n",
    "                if (lcb_t[gb2.groups[G_t]].min() > history_best_lcb):\n",
    "                    history_best_l = G_t\n",
    "                    history_best_lcb = lcb_t[gb2.groups[G_t]].min()\n",
    "                    history_best_l_mean = gb2.true_means[gb2.groups[history_best_l]].min()\n",
    "                gb2.one_iteration(np.array([a_t]))\n",
    "\n",
    "            # There are 3 choices for regret comparison: gb2_minmax_mean, gb2_minmax_lcb, history_best_lcb\n",
    "            if pulls > 0:\n",
    "                ## gb2_minmax_mean\n",
    "                gb2_summary['gb2_minmax_mean_val'].append(gb2_minmax_mean_G_mean)\n",
    "                gb2_summary['gb2_minmax_mean_G'].append(gb2_minmax_mean_G)\n",
    "                gb2_summary['gb2_minmax_mean_regret'].append(true_optimal_min - gb2_minmax_mean_G_mean)\n",
    "\n",
    "                ## gb2_minmax_lcb\n",
    "                gb2_summary['gb2_minmax_lcb_val'].append(gb2_minmax_lcb_G_mean)\n",
    "                gb2_summary['gb2_minmax_lcb_G'].append(gb2_minmax_lcb_G)\n",
    "                gb2_summary['gb2_minmax_lcb_regret'].append(true_optimal_min - gb2_minmax_lcb_G_mean)\n",
    "\n",
    "                ## history_best_lcb\n",
    "                gb2_summary['gb2_history_lcb_val'].append(history_best_l_mean)\n",
    "                gb2_summary['gb2_history_lcb_G'].append(history_best_l)\n",
    "                gb2_summary['gb2_history_lcb_regret'].append(true_optimal_min - history_best_l_mean)\n",
    "\n",
    "    #         print(gb1_summary, gb2_summary)\n",
    "            # One iteration for SE (end)\n",
    "            gb1.one_iteration(a)\n",
    "            if np.array_equal(np.tile(a, (len(c), 1)), m[c]): # Check if all m_i^G have identical elements\n",
    "                print('Multiple optimal groups found')\n",
    "                break\n",
    "            if (gb1.iter > 100000):\n",
    "                print(f'bad: {m, c, a}')\n",
    "                break\n",
    "        print(f'{k}: {c} // {gb2_minmax_lcb_G}')\n",
    "\n",
    "        gap_result[k] = {'gb1_summary': gb1_summary, 'gb2_summary': gb2_summary}\n",
    "\n",
    "    result[gap] = gap_result\n",
    "\n",
    "with open(f'Results/regret_result_c={c_val}.pickle', 'wb') as handle:\n",
    "    pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
