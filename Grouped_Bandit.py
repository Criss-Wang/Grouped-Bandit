'''
Defines the grouped bandit class (gb) that represents the structure of grouped bandit defined in the paper.
This class is for creating instances of grouped bandits to be run on different algorithms.
For simplicity, we only consider 1-D finite and discrete case.

In our experiments, we do not use the groups and arm reward means automatically generated by the gb class.
Instead, we use functions from util.py to generate these groups and means as input params when the gb class is instantiated.
However, we do utilise several key features/functions of the class in our algorithm. You may refer to

'''

import numpy as np
import math
from scipy.stats import bernoulli

class gb:
    
    def __init__(self,
        num_groups=5,
        num_arms=20,
        error_rate=0.01, ## (0, 0.11)
        eta=0.1, ## (0, 1)
        c=1, ## confidence param
        dist='bernoulli', ## {bernoulli or normal}
        gap=-1,
        means=np.array([]),
        groups=np.array([])) -> None:
        
        self.dist = dist
        self.c = c
        self.true_std = 0.25 # param only meaningful under normal distribution
        self.num_groups = num_groups
        self.num_arms = num_arms
        self.individual_arm_pulls = np.zeros(num_arms)
        self.empirical_means = np.zeros(num_arms)
        self.iter = 0
        
        new_groups = self.internal_generate_groups(num_groups, num_arms)
        new_means = np.random.rand(num_arms)
        
        if groups.shape[0] != num_groups:
            self.groups = new_groups
        else:
            new_groups = groups
            self.groups = groups
        
        if means.size != num_arms:
            if gap > 0:
                self.true_means = self.adjust_gap(gap, new_groups, new_means)
            else:
                self.true_means = new_means
        else:
            self.true_means = means
        
        if (error_rate > (1/np.exp(1) * np.log(1 + eta))) or (error_rate > 0.11):
            print('Error rate out side of range (0, 1/e * log(1 + eta))')
        self.error_rate = error_rate
        self.eta = eta
        
        self.one_iteration(np.arange(num_arms))
        
    def internal_generate_groups(self, num_groups, num_arms):
        # Currently, we do not use this function in our experiments. 
        # Anyone interested in helping on improving the code is welcome to make this function work properly
        groups = []
        found = np.zeros(num_arms)
        for i in range(num_groups-1):
            group = []
            while len(group) < 1:
                for j in range(num_arms):
                    if np.random.rand() <= (1/num_groups) :
                        group.append(j)
                        found[j] = 1
            groups.append(group)
        groups.append([])
        for k in range(num_arms):
            if not found[k]:
                groups[-1].append(k)
        if len(groups[-1]) < 1:
            groups[-1] = groups[-2]
        return np.array(groups)

    def adjust_gap(self, gap, groups, means):
        # Filter out optimal groups
        optimal_min = max([min(means[g]) for g in groups])
        optimal_G = [g for g in groups if min(means[g]) == optimal_min]
        if len(optimal_G) > 1:
            print('multiple present')
        # Raise their optimal values to 0.51 (in experiment settting)
        for G in optimal_G:
            for arm in G:
                if means[arm] < 0.51:
                    means[arm] = (means[arm] + 0.51 - optimal_min)
                if len(optimal_G) > 1 and means[arm] - max(optimal_min, 0.51) < gap and means[arm] - max(optimal_min, 0.51) > 0 :
                    means[arm] = min(means[arm] + gap, 1 - 1e-9)
                    print('triggered')
        optimal_min = max(optimal_min, 0.51)
        
        adjusted = False
        groups = [g for g in groups if g not in optimal_G]
        for g in groups:
            ## Ensure inter-group gap is large
            group_min = min(means[g])
            while (group_min != optimal_min) and optimal_min - group_min < gap:
                indices = [i for i, j in enumerate(g) if means[j] == group_min]
                for idx in indices:
                    means[g[idx]] = max(means[g[idx]] - gap, 1e-9)
                group_min = min(means[g])
                adjusted = True
            if not adjusted:
                means[g[0]] = optimal_min - gap
                adjusted = True
            
        return means
        
    def find_true_objectives(self):
        '''
        Identify the true optimal group.
        '''
        f = lambda g: min(self.true_means[g])
        idx = 0
        max_val = -math.inf
        current_max = max_val
        group_min = np.vectorize(f)(self.groups)
        res = []
        while current_max >= max_val:
            idx = group_min.argmax()
            if max_val <= -math.inf:
                max_val = group_min[idx]
            group_min[idx] = -math.inf
            current_max = group_min.max()
            res.append(idx)
        return res
    
    def confidence_U(self, t, n):
        '''
        Empirical confidence bound (1/sqrt(T)).
        '''
        U = self.c / np.sqrt(t)
        return U
    
    def confidence_U_theoretical(self, t, n):
        '''
        Theoretical confidence bound as specified in the paper.
        '''
        U = (1 + np.sqrt(self.eta)) * np.sqrt((1+self.eta)/(2*t)*np.log(np.log((1+self.eta)*t)/(self.error_rate/n)))
        return U
        
    
    def update_arm(self, idx):
        '''
        Pull new arms specified by idx, then update the empirical means and individual arm pulls.
        '''
        if self.dist == 'bernoulli':
            val = self.true_means[idx] > np.random.rand()
        else:
            val = np.random.normal(self.true_means[idx], self.true_std)
        individual_arm_pull =  self.individual_arm_pulls[idx]
        self.empirical_means[idx] = (self.empirical_means[idx] * individual_arm_pull + val) / (individual_arm_pull + 1)
        self.individual_arm_pulls[idx] = individual_arm_pull + 1
        
    def one_iteration(self, target_arms):
        self.iter += 1
        for a in target_arms:
            self.update_arm(a)
        
    def display_result(self):
        '''
        Output results include
        - Total interations used
        - Total amount of arm pulls up to current iteration
        - The true optimal group(s).
        '''
        print(f'total iterations:{self.iter}')
        print(f'true optimal groups: {self.find_true_objectives()}')
        print(f'total arm pulls: {self.compute_total_arm_pulls()}')

    def compute_total_arm_pulls(self):
        return self.individual_arm_pulls.sum()
        